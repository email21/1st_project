import os
import pandas as pd
from typing import Dict, List, Any 
from langchain.embeddings.base import Embeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_upstage import ChatUpstage # type: ignore
from langchain_core.messages import HumanMessage, AIMessage
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from dotenv import load_dotenv

load_dotenv()

class EnhancedKakaoEmbeddings(Embeddings):
    def __init__(self, batch_size=32, show_progress=True):
        from sentence_transformers import SentenceTransformer 
        self.encoder = SentenceTransformer("upskyy/kf-deberta-multitask") # í•œêµ­ì–´ ê¸ˆìœµ ë„ë©”ì¸ì— íŠ¹í™”ëœ DeBERTa ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸, í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì œê³µ
        self.batch_size = batch_size  # ì„ë² ë”© ì²˜ë¦¬ ì‹œ í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        self.show_progress = show_progress
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]: # ë¦¬í„´í„´ê°’: ê° ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """ë¬¸ì„œ ì„ë² ë”© - LangChain í˜¸í™˜"""
        embeddings = self.encoder.encode(  # SentenceTransformerì˜ encode ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±
            texts, 
            batch_size=self.batch_size,
            show_progress_bar=self.show_progress,
            normalize_embeddings=True,  # ì„ë² ë”© ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì— ìµœì í™”
            convert_to_numpy=True  # ê²°ê³¼ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜ (í›„ì²˜ë¦¬ í¸ì˜ì„±)
        )
        return embeddings.tolist()
    
    def embed_query(self, text: str) -> List[float]:
        """ë‹¨ì¼ ì¿¼ë¦¬ ì„ë² ë”© - LangChain í˜¸í™˜"""
        embedding = self.encoder.encode(
            [text], # ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ì „ë‹¬í•©ë‹ˆë‹¤ (API ì¼ê´€ì„±)
            normalize_embeddings=True,
            convert_to_numpy=True
        )[0]  # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(ë‹¨ì¼ ì„ë² ë”©)ë¥¼ ì¶”ì¶œ
        return embedding.tolist()  #NumPy ë°°ì—´ì„ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë¦¬í„´

class FinancialRecommendationSystem:
    def __init__(self):
        self.vector_store = None
        self.chat_model = None
        self.retriever = None
        self.rag_chain = None
        self.conversation_history = []
        self._initialize_system()
    
    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self._load_financial_data()          
            self.chat_model = ChatUpstage( # ChatUpstage ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ LLM API ì—°ê²°
                api_key=os.getenv("SOLAR_API_KEY"),
                model="solar-1-mini-chat"
            )
            
            # RAG ì²´ì¸ êµ¬ì„±
            self._setup_rag_chain()
            print("âœ… ê¸ˆìœµìƒí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise            
        
    def _load_financial_data(self):
        """ê¸ˆìœµìƒí’ˆ ë°ì´í„° ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•"""
        documents = []
        # data_dir = "../data/processed"
        data_dir = "data/processed"
        product_files = {
            'deposit': 'deposit_processed.csv',
            'saving': 'saving_processed.csv', 
            'annuity': 'annuity_processed.csv',
            'mortgage': 'mortgage_processed.csv',
            'rent': 'rent_processed.csv',
            'credit': 'credit_processed.csv'
        }
        
        for product_type, filename in product_files.items():
            filepath = os.path.join(data_dir, filename)
            if os.path.exists(filepath):
                try:
                    df = pd.read_csv(filepath)
                    for _, row in df.iterrows():
                        doc = {
                            'product_type': product_type,
                            'company': row.get('kor_co_nm', ''),
                            'product_name': row.get('fin_prdt_nm', ''),
                            'search_text': row.get('search_text', ''),
                            'raw_data': row.to_dict()
                        }
                        documents.append(doc)
                except Exception as e:
                    print(f"âŒ {product_type} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        embeddings_model = EnhancedKakaoEmbeddings(
            batch_size=32,
            show_progress=True
        )   
        texts = [doc['search_text'] for doc in documents]  # ê²€ìƒ‰ í…ìŠ¤íŠ¸ ì¤€ë¹„

         # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±, í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜, FAISS ì¸ë±ìŠ¤ êµ¬ì¶• 
        self.vector_store = FAISS.from_texts(
            texts=texts,
            embedding=embeddings_model, 
            metadatas=documents # ìƒí’ˆ ë©”íƒ€ë°ì´í„°
        )
         # ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • (ìƒìœ„ 3ê°œ ë¬¸ì„œ ë¦¬í„´) 3->5ë¡œ ë³€ê²½(0730)
        self.retriever = self.vector_store.as_retriever(k=5) # ë²¡í„° ê²€ìƒ‰ì—ì„œ ë°˜í™˜í™˜í•  ìƒìœ„ ìœ ì‚¬ ë¬¸ì„œì˜ ê°œìˆ˜, ì´ 3ê°œ ë¬¸ì„œê°€ RAG ì²´ì¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        self.documents = documents
        
        print(f"ğŸ“Š ì´ {len(documents)}ê°œ ìƒí’ˆ ë¡œë“œ ì™„ë£Œ")   

    def _setup_rag_chain(self):        
        """RAG ì²´ì¸ êµ¬ì„±"""
        # ì§ˆë¬¸ ì¬êµ¬ì„± í”„ë¡¬í”„íŠ¸
        multiturn_system_prompt = """
        ê¸ˆìœµìƒí’ˆ ìƒë‹´ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´ì „ ëŒ€í™” ë§¥ë½ê³¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ì™„ì „í•œ ì§ˆë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.

        **ì¬êµ¬ì„± ì›ì¹™:**
        1. ëŒ€ëª…ì‚¬ ì²˜ë¦¬: "ê·¸ ìƒí’ˆ", "ì´ ëŒ€ì¶œ" â†’ êµ¬ì²´ì ì¸ ìƒí’ˆëª…ìœ¼ë¡œ êµì²´
        2. ë§¥ë½ ì˜ì¡´ ì§ˆë¬¸: "ê¸ˆë¦¬ê°€ ì–´ë–¤ë°?" â†’ "ì•ì„œ ì¶”ì²œí•œ [ìƒí’ˆëª…]ì˜ ê¸ˆë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
        3. íšŒì‚¬ ê´€ë ¨ ì§ˆë¬¸: "[íšŒì‚¬ëª…] ëŒ€ì¶œ ê¸ˆë¦¬ëŠ”?" â†’ "[íšŒì‚¬ëª…]ì˜ [ì•ì„œ ì–¸ê¸‰í•œ ìƒí’ˆëª…] ëŒ€ì¶œ ê¸ˆë¦¬ëŠ”?"

        **ì¬êµ¬ì„± ì˜ˆì‹œ:**
        - ì´ì „: "ì‹ í•œì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ì¶”ì²œ"
        - í˜„ì¬: "ê¸ˆë¦¬ê°€ ì–´ë–¤ë°?" 
        - ì¬êµ¬ì„±: "ì‹ í•œì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œì˜ ê¸ˆë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"

        **ì¤‘ìš”:** ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ìƒí’ˆëª…ê³¼ íšŒì‚¬ëª…ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
        """
        multiturn_prompt = ChatPromptTemplate.from_messages([ # LangChainì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            ("system", multiturn_system_prompt), # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì¬êµ¬ì„± ì§€ì¹¨ ì „ë‹¬
            MessagesPlaceholder("chat_history"),  # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë™ì ìœ¼ë¡œ ì‚½ì…í•˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë”
            ("human", "{input}"), # í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì‚½ì…í•˜ëŠ” í…œí”Œë¦¿
        ])
        
        # ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ëŠ” ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±, self.retriever:ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ (FAISS ê¸°ë°˜, k=3)
        history_aware_retriever = create_history_aware_retriever( # LangChainì˜ íˆìŠ¤í† ë¦¬ ì¸ì§€ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± í•¨ìˆ˜
            self.chat_model, self.retriever, multiturn_prompt
        )
        # ì œì•½ì‚¬í•­ ì¶”ê°€ 
        rag_system_prompt = """
            ë‹¹ì‹ ì€ ê¸ˆìœµìƒí’ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            
            **ì ˆëŒ€ ì œì•½ì‚¬í•­:** 
            - ì˜¤ì§ ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ì— ëª…ì‹œëœ ìƒí’ˆë§Œ ì¶”ì²œí•˜ì„¸ìš”
            - ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ìƒí’ˆëª…ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
            - "ê²€ìƒ‰ëœ ìƒí’ˆ ì¤‘ì—ì„œ" ë¼ëŠ” í‘œí˜„ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”

            **ë‹µë³€ ì›ì¹™:**
            1. ì´ì „ ëŒ€í™” ë§¥ë½ì„ í•­ìƒ ê³ ë ¤í•˜ì—¬ ì¼ê´€ëœ ë‹µë³€ ì œê³µ
            2. "í‘œë¡œ ì •ë¦¬", "ëª©ë¡ìœ¼ë¡œ", "ìš”ì•½í•´ì¤˜" ìš”ì²­ ì‹œ â†’ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€
            3. "ì§€ê¸ˆê¹Œì§€ ì¶”ì²œí•œ", "ì•ì„œ ë§í•œ" ë“± â†’ ì´ì „ ëŒ€í™” ë‚´ìš© ì°¸ì¡°í•˜ì—¬ ë‹µë³€
            4. ìƒˆë¡œìš´ ì¶”ì²œ ìš”ì²­ ì‹œ â†’ ğŸ“ í˜•ì‹ìœ¼ë¡œ ìƒí’ˆ ì¶”ì²œ

            **í‘œ ìš”ì²­ ì‹œ ì˜ˆì‹œ:**
            | ìˆœë²ˆ | ìƒí’ˆëª… | ê¸ˆìœµíšŒì‚¬ | íŠ¹ì§• |
            |------|--------|----------|------|
            | 1 | [ì´ì „ ì¶”ì²œ ìƒí’ˆ1] | [íšŒì‚¬] | [ê°„ë‹¨ ì„¤ëª…] |

            **ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ë˜, ì‚¬ìš©ìì˜ ìš”ì²­ í˜•íƒœì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”.**
                """
               
        rag_prompt = ChatPromptTemplate.from_messages([
            ("system", rag_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
            ("system", "ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤:\n{context}")
        ])
        # ì „ì²´ RAG ì²´ì¸ êµ¬ì„±
        question_answer_chain = create_stuff_documents_chain(self.chat_model, rag_prompt)
        self.rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)        
       
    def is_reference_query(self, query: str) -> bool:
        """LLMì„ ì‚¬ìš©í•´ ì´ì „ ëŒ€í™” ì°¸ì¡° ì—¬ë¶€ íŒë‹¨"""
        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ì¡°í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”:
        "{query}"
        
        ì´ì „ ëŒ€í™” ì°¸ì¡°í•˜ëŠ” ê²½ìš°: True
        ìƒˆë¡œìš´ ì§ˆë¬¸ì¸ ê²½ìš°: False
        
        ë‹µë³€ì€ True ë˜ëŠ” Falseë§Œ í•˜ì„¸ìš”.
        """
        
        response = self.chat_model.invoke([HumanMessage(content=prompt)])
        return "True" in response.content
    
    def _format_conversation_history(self) -> str:
        """ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        formatted = ""
        for msg in self.conversation_history:
            if isinstance(msg, HumanMessage):
                formatted += f"ì‚¬ìš©ì: {msg.content}\n"
            elif isinstance(msg, AIMessage):
                formatted += f"ì‹œìŠ¤í…œ: {msg.content}\n"
        return formatted      

    def get_recommendation(self, query: str) -> Dict[str, Any]:
        """ì¶”ì²œ ê²°ê³¼ ë¦¬í„´ (ë©€í‹°í„´ ì§€ì›)"""
        try:           
            # ì´ì „ ëŒ€í™” ì°¸ì¡° ì—¬ë¶€ íŒë‹¨
            is_reference = self.is_reference_query(query)
        
            if is_reference and self.conversation_history:
                # ì´ì „ ëŒ€í™” ì°¸ì¡° ì§ˆë¬¸ì¸ ê²½ìš° - ë²¡í„° ê²€ìƒ‰ ì—†ì´ ëŒ€í™” ê¸°ë¡ë§Œ í™œìš©
                prompt = f"""
                ì´ì „ ëŒ€í™” ê¸°ë¡:
                {self._format_conversation_history()}                
                í˜„ì¬ ì§ˆë¬¸: {query}                
                ì´ì „ ëŒ€í™”ì—ì„œ ì¶”ì²œí•œ ìƒí’ˆë“¤ì„ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
                ìƒˆë¡œìš´ ìƒí’ˆì„ ì¶”ì²œí•˜ì§€ ë§ê³ , ê¸°ì¡´ ì¶”ì²œ ìƒí’ˆë“¤ë§Œ í™œìš©í•˜ì„¸ìš”.
                """            
                response = self.chat_model.invoke([HumanMessage(content=prompt)])
                result_answer = response.content
            else:
                # ìƒˆë¡œìš´ ì§ˆë¬¸ì¸ ê²½ìš° - RAG ë°©ì‹ ì‚¬ìš©
                result = self.rag_chain.invoke({
                    'input': query,
                    'chat_history': self.conversation_history  # ì´ì „ ëŒ€í™”ê¸°ë¡ ì „ë‹¬
                })
                # ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ ì¶”ê°€
                retrieved_docs = result.get('context', [])  
                if not retrieved_docs or len(retrieved_docs) == 0:
                    result_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì„ êµ¬ì¶•ëœ ë°ì´í„°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì¡°ê±´ì„ ë§ì”€í•´ì£¼ì‹œê±°ë‚˜ ë‹¤ë¥¸ ìƒí’ˆ ìœ í˜•ìœ¼ë¡œ ë¬¸ì˜í•´ë³´ì‹œê² ì–´ìš”?"
                else:
                    result_answer = result['answer']         
           
            #  ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ë©€í‹°í„´ ì§€ì›)
            self.conversation_history.append(HumanMessage(content=query))
            self.conversation_history.append(AIMessage(content=result_answer))
            
            # ëŒ€í™” ê¸°ë¡ ê¸¸ì´ ì œí•œ (ìµœê·¼ 10í„´ë§Œ ìœ ì§€)
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]            
            
            return {
                'status': 'success',
                'recommendation': result_answer,
                'conversation_turns': len(self.conversation_history) // 2
            }     
                    
            # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ë©€í‹°í„´ ì§€ì›) ì´í›„ ì¶”ê°€
            print(f"=========== [DEBUG][ë°±ì—”ë“œ] get_recommendation í˜¸ì¶œ í›„ ëŒ€í™” ê¸¸ì´: {len(self.conversation_history)}, í„´ìˆ˜: {len(self.conversation_history)//2}")
            for idx, msg in enumerate(self.conversation_history):
                print(f"  [{idx}] {msg.__class__.__name__}: {msg.content}")
                
        except Exception as e:
            return {'status': 'error', 'error': str(e)}              

    def reset_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []
        print("=======--- [DEBUG] [ë°±ì—”ë“œ] ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. --- financial_rag_system.py")
        print("--- ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. --- financial_rag_system.py")
        
    def sync_conversation_history(self, streamlit_conversation: List[Dict]):
        """Streamlit ëŒ€í™” ê¸°ë¡ê³¼ RAG ì‹œìŠ¤í…œ ë™ê¸°í™”"""
        self.conversation_history = []
        
        for message in streamlit_conversation:
            if message["role"] == "user":
                self.conversation_history.append(HumanMessage(content=message["content"]))
            else:
                self.conversation_history.append(AIMessage(content=message["content"]))
        
        print(f"ëŒ€í™” ê¸°ë¡ ë™ê¸°í™” ì™„ë£Œ: {len(self.conversation_history)}ê°œ ë©”ì‹œì§€")
        
         # ì‹¤ì œ ëˆ„ì ëœ ë©”ì‹œì§€ ëª©ë¡ í™•ì¸
        print("====================== [DEBUG][ë°±ì—”ë“œ] ë™ê¸°í™”ëœ ì „ì²´ ëŒ€í™” ë‚´ì—­:")
        for idx, msg in enumerate(self.conversation_history):
            print(f"  {idx}ë²ˆì§¸({type(msg).__name__}): {msg.content}")