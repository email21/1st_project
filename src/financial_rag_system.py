import os
import pandas as pd
from typing import Dict, List, Any, Optional  # 
from langchain.embeddings.base import Embeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_upstage import ChatUpstage # type: ignore
from langchain_core.messages import HumanMessage, AIMessage
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from dotenv import load_dotenv
import warnings
import streamlit as st

load_dotenv()

class EnhancedKakaoEmbeddings(Embeddings):
    def __init__(self, batch_size=32, show_progress=True):
        from sentence_transformers import SentenceTransformer 
        self.encoder = SentenceTransformer("upskyy/kf-deberta-multitask") # í•œêµ­ì–´ ê¸ˆìœµ ë„ë©”ì¸ì— íŠ¹í™”ëœ DeBERTa ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸, í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì œê³µ
        self.batch_size = batch_size  # ì„ë² ë”© ì²˜ë¦¬ ì‹œ í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        self.show_progress = show_progress
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]: # ë¦¬í„´í„´ê°’: ê° ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """ë¬¸ì„œ ì„ë² ë”© - LangChain í˜¸í™˜"""
        embeddings = self.encoder.encode(  # SentenceTransformerì˜ encode ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±
            texts, 
            batch_size=self.batch_size,
            show_progress_bar=self.show_progress,
            normalize_embeddings=True,  # ì„ë² ë”© ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì— ìµœì í™”
            convert_to_numpy=True  # ê²°ê³¼ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜ (í›„ì²˜ë¦¬ í¸ì˜ì„±)
        )
        return embeddings.tolist()
    
    def embed_query(self, text: str) -> List[float]:
        """ë‹¨ì¼ ì¿¼ë¦¬ ì„ë² ë”© - LangChain í˜¸í™˜"""
        embedding = self.encoder.encode(
            [text], # ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ì „ë‹¬í•©ë‹ˆë‹¤ (API ì¼ê´€ì„±)
            normalize_embeddings=True,
            convert_to_numpy=True
        )[0]  # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(ë‹¨ì¼ ì„ë² ë”©)ë¥¼ ì¶”ì¶œ
        return embedding.tolist()  #NumPy ë°°ì—´ì„ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ë¦¬í„´

class FinancialRecommendationSystem:
    def __init__(self):
        self.vector_store = None
        self.chat_model = None
        self.retriever = None
        self.rag_chain = None
        self.conversation_history = []
        self._initialize_system()
    
    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self._load_financial_data()          
            self.chat_model = ChatUpstage( # ChatUpstage ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ LLM API ì—°ê²°
                api_key=os.getenv("SOLAR_API_KEY"),
                model="solar-1-mini-chat"
            )
            
            # RAG ì²´ì¸ êµ¬ì„±
            self._setup_rag_chain()
            print("âœ… ê¸ˆìœµìƒí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _map_category_to_type(self, category: str) -> str:
        """ì‚¬ìš©ì ì¹´í…Œê³ ë¦¬ë¥¼ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë§¤í•‘"""
        if 'ì •ê¸°ì˜ˆê¸ˆ' in category:
            return 'deposit'
        elif 'ì ê¸ˆ' in category:
            return 'saving'
        elif category == 'ì˜ˆê¸ˆ':  # ë‹¨ìˆœ 'ì˜ˆê¸ˆ'ì€ ì •ê¸°ì˜ˆê¸ˆìœ¼ë¡œ ì²˜ë¦¬
            return 'deposit'
        elif 'ì €ì¶•' in category and 'ì ê¸ˆ' not in category:
            return 'deposit'
        elif 'ì—°ê¸ˆ' in category:
            return 'annuity'
        elif 'ì£¼íƒë‹´ë³´' in category:
            return 'mortgage'
        elif 'ì „ì„¸' in category:
            return 'rent'
        elif 'ì‹ ìš©ëŒ€ì¶œ' in category or 'ê°œì¸ì‹ ìš©' in category:
            return 'credit'
        return ''
       
    def _filter_by_category(self, context: List[Any], analysis: Dict[str, Any]):
        """ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§"""
        category = analysis.get('product_category', '')
        if not category:
            return context
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        target_type = self._map_category_to_type(category)
        if not target_type:
            return context
        
        # ì •í™•í•œ ë§¤ì¹­ë§Œ í—ˆìš©
        filtered = []
        for doc in context:
            if hasattr(doc, 'metadata'):
                doc_type = doc.metadata.get('product_type', '')
                if doc_type == target_type:
                    filtered.append(doc)
                    
        print(f"ì¹´í…Œê³ ë¦¬ '{category}' â†’ íƒ€ì… '{target_type}' í•„í„°ë§: {len(filtered)}ê°œ")
        return filtered
    
    def _load_financial_data(self):
        """ê¸ˆìœµìƒí’ˆ ë°ì´í„° ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•"""
        documents = []
        data_dir = "../data/processed"
        product_files = {
            'deposit': 'deposit_processed.csv',
            'saving': 'saving_processed.csv', 
            'annuity': 'annuity_processed.csv',
            'mortgage': 'mortgage_processed.csv',
            'rent': 'rent_processed.csv',
            'credit': 'credit_processed.csv'
        }
        
        for product_type, filename in product_files.items():
            filepath = os.path.join(data_dir, filename)
            if os.path.exists(filepath):
                try:
                    df = pd.read_csv(filepath)
                    for _, row in df.iterrows():
                        doc = {
                            'product_type': product_type,
                            'company': row.get('kor_co_nm', ''),
                            'product_name': row.get('fin_prdt_nm', ''),
                            'search_text': row.get('search_text', ''),
                            'raw_data': row.to_dict()
                        }
                        documents.append(doc)
                except Exception as e:
                    print(f"âŒ {product_type} ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        embeddings_model = EnhancedKakaoEmbeddings(
            batch_size=32,
            show_progress=True
        )   
        texts = [doc['search_text'] for doc in documents]  # ê²€ìƒ‰ í…ìŠ¤íŠ¸ ì¤€ë¹„

         # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±, í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜, FAISS ì¸ë±ìŠ¤ êµ¬ì¶• 
        self.vector_store = FAISS.from_texts(
            texts=texts,
            embedding=embeddings_model, 
            metadatas=documents # ìƒí’ˆ ë©”íƒ€ë°ì´í„°
        )
         # ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • (ìƒìœ„ 3ê°œ ë¬¸ì„œ ë¦¬í„´)
        self.retriever = self.vector_store.as_retriever(k=3) # ë²¡í„° ê²€ìƒ‰ì—ì„œ ë°˜í™˜í™˜í•  ìƒìœ„ ìœ ì‚¬ ë¬¸ì„œì˜ ê°œìˆ˜, ì´ 3ê°œ ë¬¸ì„œê°€ RAG ì²´ì¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        self.documents = documents
        
        print(f"ğŸ“Š ì´ {len(documents)}ê°œ ìƒí’ˆ ë¡œë“œ ì™„ë£Œ")

    def _create_hybrid_recommendation(self, query: str, search_results: List[Dict], original_answer: str) -> str:
        
        """ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ + LLM ì–¸ì–´ ì²˜ë¦¬"""
        if not search_results:
            return "ê²€ìƒ‰ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
        
        # ì´ì „ ëŒ€í™” ë§¥ë½ ì¶”ê°€
        context_info = ""
        if self.conversation_history:
            last_messages = self.conversation_history[-6:]  # ìµœê·¼ 3í„´ë§Œ ì°¸ì¡°
            for msg in last_messages:
                if isinstance(msg, AIMessage) and "ğŸ“ ì¶”ì²œ ìƒí’ˆ:" in msg.content:
                    context_info = f"ì´ì „ ì¶”ì²œ ìƒí’ˆ ì •ë³´: {msg.content[:200]}..."
                    break
    
           
        # ë°ì´í„° ê¸°ë°˜ ìƒí’ˆ ì„ íƒ (ê·œì¹™ ê¸°ë°˜)
        top_product = search_results[0]
        
        # LLMìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ìƒì„±
        context = f"""
        ì¶”ì²œ ìƒí’ˆ: {top_product['product_name']}
        ê¸ˆìœµíšŒì‚¬: {top_product['company']}
        ìƒí’ˆìœ í˜•: {top_product['product_type']}
        ìœ ì‚¬ë„: {top_product['similarity_score']}
        """
        
        # LLM í™œìš©
        try:
            prompt = f"""
            {context_info}
        
        í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼: {search_results[0] if search_results else 'ì—†ìŒ'}
        ì‚¬ìš©ì ì§ˆë¬¸: {query}
        
        ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì¼ê´€ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
        
        ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”.
        
        **ê²€ìƒ‰ëœ ìƒí’ˆ ì •ë³´:**
        {context}
        
        **ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
        - ìœ„ ìƒí’ˆ ì •ë³´ë§Œì„ í™œìš©í•˜ì—¬ ì¶”ì²œ ì‘ì„±
        - ì´ì „ ëŒ€í™”ì™€ ì—°ê´€ì„±ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€
        - ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
        
        **ìƒí’ˆì„ ì¶”ì²œí•  ê²½ìš° ë‹¤ìŒ í˜•ì‹ì‹ìœ¼ë¡œ ë‹µë³€:**
        ğŸ“ **ì¶”ì²œ ìƒí’ˆ**: {top_product['product_name']}
        ğŸ“ **ê¸ˆìœµíšŒì‚¬**: {top_product['company']}
        ğŸ“ **ì¶”ì²œ ì´ìœ **: [êµ¬ì²´ì  ì´ìœ  ì„¤ëª…]
        ğŸ“ **ì£¼ì˜ì‚¬í•­**: [ê³ ë ¤ì‚¬í•­ ì•ˆë‚´]
            """
            
            llm_response = self.chat_model.invoke([HumanMessage(content=prompt)])
            return llm_response.content
            
        except Exception as e:
            # LLM ì‹¤íŒ¨ ì‹œ ì›ë³¸ RAG ë‹µë³€ ì‚¬ìš©
            print(f"í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return original_answer if original_answer else "ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def _validate_recommendation(self, recommendation: str, search_results: List[Dict]) -> bool:
        """ì¶”ì²œ ê²°ê³¼ ê²€ì¦"""
        if not search_results:
            return False
        
        # í—ˆìš©ëœ ìƒí’ˆëª…ë“¤ ì¶”ì¶œ
        allowed_products = [product['product_name'] for product in search_results]
        allowed_companies = [product['company'] for product in search_results]
        
        # ì¶”ì²œ ë‚´ìš©ì— í—ˆìš©ëœ ìƒí’ˆë§Œ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        for product_name in allowed_products:
            if product_name in recommendation:
                return True
        
        return False

    def _filter_validated_results(self, search_results: List[Dict]) -> List[Dict]:
        """ê²€ì¦ëœ ê²°ê³¼ë§Œ í•„í„°ë§"""
        validated = []
        for product in search_results:
            # ê¸°ë³¸ í•„ë“œ ê²€ì¦
            if (product.get('product_name') and 
                product.get('company') and 
                product.get('product_type')):
                validated.append(product)
        
        return validated


    
    def _setup_rag_chain(self):        
        """RAG ì²´ì¸ êµ¬ì„±"""
        # ì§ˆë¬¸ ì¬êµ¬ì„± í”„ë¡¬í”„íŠ¸
        multiturn_system_prompt = """
        ê¸ˆìœµìƒí’ˆ ìƒë‹´ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´ì „ ëŒ€í™” ë§¥ë½ê³¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ì™„ì „í•œ ì§ˆë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.

        **ì¬êµ¬ì„± ì›ì¹™:**
        1. ëŒ€ëª…ì‚¬ ì²˜ë¦¬: "ê·¸ ìƒí’ˆ", "ì´ ëŒ€ì¶œ" â†’ êµ¬ì²´ì ì¸ ìƒí’ˆëª…ìœ¼ë¡œ êµì²´
        2. ë§¥ë½ ì˜ì¡´ ì§ˆë¬¸: "ê¸ˆë¦¬ê°€ ì–´ë–¤ë°?" â†’ "ì•ì„œ ì¶”ì²œí•œ [ìƒí’ˆëª…]ì˜ ê¸ˆë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
        3. íšŒì‚¬ ê´€ë ¨ ì§ˆë¬¸: "[íšŒì‚¬ëª…] ëŒ€ì¶œ ê¸ˆë¦¬ëŠ”?" â†’ "[íšŒì‚¬ëª…]ì˜ [ì•ì„œ ì–¸ê¸‰í•œ ìƒí’ˆëª…] ëŒ€ì¶œ ê¸ˆë¦¬ëŠ”?"

        **ì¬êµ¬ì„± ì˜ˆì‹œ:**
        - ì´ì „: "ì‹ í•œì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œ ì¶”ì²œ"
        - í˜„ì¬: "ê¸ˆë¦¬ê°€ ì–´ë–¤ë°?" 
        - ì¬êµ¬ì„±: "ì‹ í•œì€í–‰ ì „ì„¸ìê¸ˆëŒ€ì¶œì˜ ê¸ˆë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"

        **ì¤‘ìš”:** ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ìƒí’ˆëª…ê³¼ íšŒì‚¬ëª…ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
        """
        multiturn_prompt = ChatPromptTemplate.from_messages([ # LangChainì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            ("system", multiturn_system_prompt), # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì¬êµ¬ì„± ì§€ì¹¨ ì „ë‹¬
            MessagesPlaceholder("chat_history"),  # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë™ì ìœ¼ë¡œ ì‚½ì…í•˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë”
            ("human", "{input}"), # í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì‚½ì…í•˜ëŠ” í…œí”Œë¦¿
        ])
        
        # ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ëŠ” ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±, self.retriever:ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ (FAISS ê¸°ë°˜, k=3)
        history_aware_retriever = create_history_aware_retriever( # LangChainì˜ íˆìŠ¤í† ë¦¬ ì¸ì§€ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± í•¨ìˆ˜
            self.chat_model, self.retriever, multiturn_prompt
        )
        
        rag_system_prompt = """
            ë‹¹ì‹ ì€ ê¸ˆìœµìƒí’ˆ ì „ë¬¸ê°€ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

            **ì§ˆë¬¸ ìœ í˜•ë³„ ë‹µë³€ ë°©ì‹:**

            **1. ìƒí’ˆ ì¶”ì²œ ìš”ì²­ì‹œë§Œ ë‹¤ìŒ êµ¬ì¡° ì‚¬ìš©:**
            ğŸ“ **ìƒí™© ë¶„ì„**: ì‚¬ìš©ìì˜ ë‹ˆì¦ˆì™€ ìƒí™©ì„ ê°„ë‹¨íˆ ìš”ì•½
            ğŸ“ **ì¶”ì²œ ìƒí’ˆ**: ê°€ì¥ ì í•©í•œ ìƒí’ˆ 1ê°œ ì„ ì •
            ğŸ“ **ê¸ˆìœµíšŒì‚¬**: í•´ë‹¹ ìƒí’ˆì„ ì œê³µí•˜ëŠ” ê¸ˆìœµíšŒì‚¬
            ğŸ“ **ì¶”ì²œ ì´ìœ **: êµ¬ì²´ì  ê·¼ê±°
            ğŸ“ **ì£¼ì˜ì‚¬í•­**: ê°€ì… ì „ í™•ì¸ì‚¬í•­
            ğŸ“ **ë‹¤ìŒ ë‹¨ê³„**: ì‹¤ì œ ê°€ì… ì•ˆë‚´

            **2. ì •ë³´ ë¬¸ì˜, ì„¤ëª… ìš”ì²­ì‹œ:**
            - ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì´ê³  ëª…í™•í•œ ë‹µë³€
            - í•„ìš”ì‹œ ê´€ë ¨ ìƒí’ˆ ì •ë³´ ì œê³µ (ì¶”ì²œ í˜•íƒœ ì•„ë‹˜)
            - ì¶”ê°€ ì§ˆë¬¸ ìœ ë„

            **3. ì´ì „ ëŒ€í™” ì°¸ì¡° ì§ˆë¬¸ì‹œ:**
            - ì´ì „ì— ì–¸ê¸‰ëœ ìƒí’ˆ/ì •ë³´ë¥¼ ì •í™•íˆ ì°¸ì¡°
            - ì¶”ì²œ í˜•íƒœê°€ ì•„ë‹Œ ì„¤ëª… í˜•íƒœë¡œ ë‹µë³€

            **ë‹µë³€ íŒë‹¨ ê¸°ì¤€:**
            - "ì¶”ì²œí•´ì¤˜", "ì•Œë ¤ì¤˜", "ì–´ë–¤ ìƒí’ˆì´ ì¢‹ì„ê¹Œ" â†’ ì¶”ì²œ í˜•íƒœ
            - "ì„¤ëª…í•´ì¤˜", "ì •ë³´ ì•Œë ¤ì¤˜", "ë­ì˜€ëŠ”ë°" â†’ ì •ë³´ ì œê³µ í˜•íƒœ
         
            4.ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "ì œê³µëœ ë°ì´í„°ì—ì„œ ì¡°ê±´ì— ë§ëŠ” ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¡œ ë‹µë³€

            **ë‹µë³€ í†¤**: ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ, ì¹œê·¼í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ
                    """
        
        rag_prompt = ChatPromptTemplate.from_messages([
            ("system", rag_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
            ("system", "ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œë“¤:\n{context}")
        ])
        # ì „ì²´ RAG ì²´ì¸ êµ¬ì„±
        question_answer_chain = create_stuff_documents_chain(self.chat_model, rag_prompt)
        self.rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
    
    def _create_hybrid_recommendation(self, query: str, search_results: List[Dict], original_answer: str, analysis: Dict) -> str:
        """ì‚¬ìš©ì ì˜ë„ì— ë”°ë¥¸ ë‹µë³€ ìƒì„±"""   
        if not search_results:   # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
            return "ê²€ìƒ‰ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."    
      
        context_info = ""   # ì´ì „ ëŒ€í™” ë§¥ë½ ì¶”ê°€
        if self.conversation_history:
            last_messages = self.conversation_history[-6:]  # ìµœê·¼ 3í„´ë§Œ ì°¸ì¡°
            for msg in last_messages:
                if isinstance(msg, AIMessage) and "ğŸ“ ì¶”ì²œ ìƒí’ˆ:" in msg.content:
                    context_info = f"ì´ì „ ì¶”ì²œ ìƒí’ˆ ì •ë³´: {msg.content[:200]}..."
                    break
        
        # ì‚¬ìš©ì ì˜ë„ ë¶„ì„
        user_intent = analysis.get('user_intent', 'information')
        product_category = analysis.get('product_category', '')
        
        # ìµœìƒìœ„ ìƒí’ˆ ì„ íƒ
        top_product = search_results[0]
        
        # ì‚¬ìš©ì ì˜ë„ì— ë”°ë¥¸ ë‹µë³€ í˜•íƒœ ê²°ì •
        if user_intent == 'information' or any(keyword in query.lower() for keyword in ['ì„¤ëª…', 'ì •ë³´', 'ë­ì˜€ëŠ”ë°', 'ì•Œë ¤ì¤˜', 'ë§ˆì§€ë§‰ìœ¼ë¡œ']):
            # ì •ë³´ ì œê³µ í˜•íƒœ
            prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            {context_info}
            
            ìƒí’ˆ ì •ë³´:
            - ìƒí’ˆëª…: {top_product.get('product_name', 'ì •ë³´ ì—†ìŒ')}
            - ê¸ˆìœµíšŒì‚¬: {top_product.get('company', 'ì •ë³´ ì—†ìŒ')}
            - ìƒí’ˆ ìœ í˜•: {top_product.get('product_type', 'ê¸°íƒ€')}
            - ìƒì„¸ ì •ë³´: {top_product.get('raw_data', {})}
            
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì´ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
            
            **ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
            - ì¶”ì²œ í˜•íƒœ(ğŸ“)ê°€ ì•„ë‹Œ ì¼ë°˜ì ì¸ ì„¤ëª… í˜•íƒœë¡œ ë‹µë³€
            - ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
            - ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì¼ê´€ëœ ë‹µë³€
            - ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©
            - ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "ìƒì„¸ ë‚´ìš©ì€ í•´ë‹¹ ê¸ˆìœµíšŒì‚¬ í™•ì¸ í•„ìš”"ë¡œ ì•ˆë‚´
            """
            
        elif user_intent == 'comparison' or 'ë¹„êµ' in query.lower():
            # ë¹„êµ í˜•íƒœ
            comparison_products = search_results[:3]  # ìƒìœ„ 3ê°œ ìƒí’ˆ ë¹„êµ
            products_info = "\n".join([
                f"- {p.get('product_name', 'ì •ë³´ ì—†ìŒ')} ({p.get('company', 'ì •ë³´ ì—†ìŒ')})"
                for p in comparison_products
            ])
            
            prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            {context_info}
            
            ë¹„êµ ëŒ€ìƒ ìƒí’ˆë“¤:
            {products_info}
            
            ìœ„ ìƒí’ˆë“¤ì„ ë¹„êµí•˜ì—¬ ê°ê°ì˜ ì¥ë‹¨ì ê³¼ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            
            **ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
            - ê° ìƒí’ˆì˜ íŠ¹ì§•ê³¼ ì¥ë‹¨ì ì„ ëª…í™•íˆ êµ¬ë¶„
            - ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ì„ íƒ ê°€ì´ë“œ ì œê³µ
            - ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©
            """
            
        else:
            # ì¶”ì²œ í˜•íƒœ (ê¸°ë³¸)
            prompt = f"""
            {context_info}
            
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ê²€ìƒ‰ëœ ìƒí’ˆ ì •ë³´:
            - ìƒí’ˆëª…: {top_product.get('product_name', 'ì •ë³´ ì—†ìŒ')}
            - ê¸ˆìœµíšŒì‚¬: {top_product.get('company', 'ì •ë³´ ì—†ìŒ')}
            - ìƒí’ˆ ìœ í˜•: {top_product.get('product_type', 'ê¸°íƒ€')}
            - ìœ ì‚¬ë„: {top_product.get('similarity_score', 0)}
            - ìƒì„¸ ì •ë³´: {top_product.get('raw_data', {})}
            
            ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì¼ê´€ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
            
            **ìƒí’ˆì„ ì¶”ì²œí•  ê²½ìš° ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€:**
            ğŸ“ **ì¶”ì²œ ìƒí’ˆ**: {top_product.get('product_name', 'ì •ë³´ ì—†ìŒ')}
            ğŸ“ **ê¸ˆìœµíšŒì‚¬**: {top_product.get('company', 'ì •ë³´ ì—†ìŒ')}
            ğŸ“ **ì¶”ì²œ ì´ìœ **: [êµ¬ì²´ì  ì´ìœ  ì„¤ëª…]
            ğŸ“ **ì£¼ì˜ì‚¬í•­**: [ê³ ë ¤ì‚¬í•­ ì•ˆë‚´]
            
            **ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
            - ìœ„ ìƒí’ˆ ì •ë³´ë§Œì„ í™œìš©í•˜ì—¬ ì¶”ì²œ ì‘ì„±
            - ì´ì „ ëŒ€í™”ì™€ ì—°ê´€ì„±ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€
            - ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ
            - ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "ìƒì„¸ ë‚´ìš©ì€ í•´ë‹¹ ê¸ˆìœµíšŒì‚¬ í™•ì¸ í•„ìš”"ë¡œ ì•ˆë‚´
            """
        
        # LLM í˜¸ì¶œ
        try:
            llm_response = self.chat_model.invoke([HumanMessage(content=prompt)])
            
            # ì‘ë‹µ ê²€ì¦
            if llm_response and llm_response.content:
                return llm_response.content
            else:
                return original_answer if original_answer else "ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        except Exception as e:
            # LLM ì‹¤íŒ¨ ì‹œ ì›ë³¸ RAG ë‹µë³€ ì‚¬ìš©
            print(f"í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return original_answer if original_answer else "ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


    def _create_information_response(self, query: str, search_results: List[Dict], original_answer: str) -> str:
        """ì •ë³´ ì œê³µ í˜•íƒœì˜ ë‹µë³€ ìƒì„±"""
        if not search_results:
            return "ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ë‹¨ìˆœ ì •ë³´ ì œê³µ í”„ë¡¬í”„íŠ¸
        info_prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì´ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”:
            {search_results[0] if search_results else 'ì •ë³´ ì—†ìŒ'}
            
            **ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
            - ì¶”ì²œ í˜•íƒœ(ğŸ“)ê°€ ì•„ë‹Œ ì¼ë°˜ì ì¸ ì„¤ëª… í˜•íƒœë¡œ ë‹µë³€
            - ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
            - í•„ìš”ì‹œ ê´€ë ¨ ìƒí’ˆ ì •ë³´ ê°„ë‹¨íˆ ì–¸ê¸‰
            """
        
        try:
            response = self.chat_model.invoke([HumanMessage(content=info_prompt)])
            return response.content
        except Exception as e:
            return f"ì •ë³´ ì œê³µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    
    def analyze_user_query(self, query: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ """
        try:
            analysis_prompt = f"""
            ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”:
            "{query}"
            
            **ì˜ë„ ë¶„ë¥˜:**
            - recommendation: ìƒí’ˆ ì¶”ì²œ ìš”ì²­ ("ì¶”ì²œí•´ì¤˜", "ì¢‹ì€ ìƒí’ˆ", "ì–´ë–¤ ê²Œ ë‚˜ì„ê¹Œ")
            - information: ì •ë³´ ë¬¸ì˜ ("ì„¤ëª…í•´ì¤˜", "ì•Œë ¤ì¤˜", "ë­ì˜€ëŠ”ë°", "ì •ë³´")
            - comparison: ìƒí’ˆ ë¹„êµ ("ë¹„êµ", "ì°¨ì´ì ", "ì–´ë–¤ ê²Œ ë”")
            - clarification: ì´ì „ ëŒ€í™” ì°¸ì¡° ("ì•„ê¹Œ", "ì „ì—", "ë§ˆì§€ë§‰ìœ¼ë¡œ")
    
            **ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ê¸°ì¤€:**
            - ì •ê¸°ì˜ˆê¸ˆ: "ì •ê¸°ì˜ˆê¸ˆ", "ì˜ˆê¸ˆ", "ëª©ëˆ ë¶ˆë¦¬ê¸°", "ì¼ì‹œë¶ˆ ì˜ˆì¹˜"
            - ì ê¸ˆ: "ì ê¸ˆ", "ë§¤ì›” ì €ì¶•", "ëª©ëˆ ëª¨ìœ¼ê¸°", "ë¶„í•  ë‚©ì…"
            - ì—°ê¸ˆì €ì¶•: "ì—°ê¸ˆ", "ë…¸í›„ ì¤€ë¹„", "ì€í‡´ ìê¸ˆ"
            - ëŒ€ì¶œ: "ëŒ€ì¶œ", "ìœµì", "ìê¸ˆ ì¡°ë‹¬"
            
            ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
            {{
            "product_category": "ë¶„ë¥˜",
            "user_intent": "recommendation/information/comparison/clarification",
            "requires_recommendation_format": true/false",
            "key_requirements": ["êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ë“¤"],
            "user_profile": "ì‚¬ìš©ì í”„ë¡œí•„ ì¶”ì •",
            "urgency": "ë†’ìŒ/ë³´í†µ/ë‚®ìŒ",
            "amount_mentioned": "ì–¸ê¸‰ëœ ê¸ˆì•¡",
            "period_mentioned": "ì–¸ê¸‰ëœ ê¸°ê°„"
             }}
                    """
            
            #  Solar API ì‚¬ìš©
            analysis_model = ChatUpstage(
                api_key=os.getenv("SOLAR_API_KEY"),
                model="solar-1-mini-chat"
            )
            
            response = analysis_model.invoke([HumanMessage(content=analysis_prompt)])
            import logging
            # ë¡œê¹… ì„¤ì • ##
            logging.basicConfig(level=logging.INFO)
            logger = logging.getLogger(__name__)            
            
            # Solar API ì‘ë‹µì„ ì‹¤ì œë¡œ íŒŒì‹±
            import json  
            try:
                parsed_result = json.loads(response.content)
                logger.info(f"----  Solar API ë¶„ì„ ê²°ê³¼: {json.dumps(parsed_result, ensure_ascii=False, indent=2)}")
                 # Streamlitì—ì„œ JSON í‘œì‹œ (ê°œë°œì ëª¨ë“œ)
                if st.session_state.get('show_debug', False):
                    st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼ (JSON)")
                    st.json(parsed_result)
        
                return parsed_result
            # except json.JSONDecodeError:
            #     return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨"}
            except json.JSONDecodeError as e:
                return {
                    "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                    "raw_response": response.content[:50] + "...",
                    "status": "json_parse_error"
                } 
        except Exception as e:
            print(f"ì¿¼ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def get_recommendation(self, query: str) -> Dict[str, Any]:
        """ì¶”ì²œ ê²°ê³¼ ë¦¬í„´ (ë©€í‹°í„´ ì§€ì›)"""
        try:
            #  ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„
            analysis = self.analyze_user_query(query)
            
             #  ì´ì „ ëŒ€í™”ì—ì„œ ì¶”ì²œí•œ ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ìœ ì§€
            if self.conversation_history:
                last_ai_message = None
                for msg in reversed(self.conversation_history):
                    if isinstance(msg, AIMessage):
                        last_ai_message = msg.content
                        break

            #  RAG ì²´ì¸ì„ í†µí•œ ì¶”ì²œ
            result = self.rag_chain.invoke({
                'input': query,
                'chat_history': self.conversation_history  # ì´ì „ ëŒ€í™”ê¸°ë¡ ì „ë‹¬
            })
            
           # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§ ì¶”ê°€
            filtered_context = self._filter_by_category(result['context'], analysis)
            if not filtered_context:
                filtered_context = result['context']
                
              #  ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… ë° ê²€ì¦
            search_results = self._format_search_results(filtered_context)
            validated_results = self._filter_validated_results(search_results)
        
            # í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìƒì„±
            if validated_results:
                hybrid_recommendation = self._create_hybrid_recommendation(               
                    query, validated_results, result['answer'], analysis
                )
            
                # ì¶”ì²œ ê²°ê³¼ ê²€ì¦
                if self._validate_recommendation(hybrid_recommendation, validated_results):
                    final_recommendation = hybrid_recommendation
                else:
                    # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ RAG ë‹µë³€ ì‚¬ìš©
                    final_recommendation = result['answer'] if result['answer'] else "ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            else:
                final_recommendation = "ê²€ìƒ‰ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."    
                

            
            #  ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ë©€í‹°í„´ ì§€ì›)
            self.conversation_history.append(HumanMessage(content=query))
            self.conversation_history.append(AIMessage(content=final_recommendation))
            
            # ëŒ€í™” ê¸°ë¡ ê¸¸ì´ ì œí•œ (ìµœê·¼ 10í„´ë§Œ ìœ ì§€)
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            return {
                'status': 'success',
                'recommendation': final_recommendation,
                'analysis': analysis,
                'search_results': search_results,
                'conversation_turns': len(self.conversation_history) // 2
            }
            
        except Exception as e:
            print(f"ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'recommendation': "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            }
    
    def _format_search_results(self, context):
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted_results = []
        for doc in context:
            if hasattr(doc, 'metadata'):
                # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ì‹¤ì œ ë²¡í„° ìœ ì‚¬ë„)
                similarity_score = self._calculate_similarity(doc)
                
                formatted_results.append({
                    'product_name': doc.metadata.get('product_name', 'ì •ë³´ ì—†ìŒ'),
                    'company': doc.metadata.get('company', 'ì •ë³´ ì—†ìŒ'),
                    'product_type': doc.metadata.get('product_type', 'ê¸°íƒ€'),
                    'similarity_score': round(similarity_score, 3),  # ì‹¤ì œ ì ìˆ˜
                    'raw_data': doc.metadata.get('raw_data', {})
                })  #  ìƒí’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ í™œìš©í•˜ê±°ë‚˜ ì¶”ê°€ ì²˜ë¦¬ê°€ í•„ìš”í•  ë•Œ
                
        # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        formatted_results.sort(key=lambda x: x['similarity_score'], reverse=True)
        return formatted_results
    
    def _calculate_similarity(self, doc):
        """ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°"""
    # FAISSì—ì„œ ì‹¤ì œ ì ìˆ˜ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ì„ì‹œë¡œ ëœë¤ ì ìˆ˜ ìƒì„±
        import random
        return random.uniform(0.7, 0.95)  # ì‹¤ì œë¡œëŠ” ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
    
    def reset_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.conversation_history = []
        print("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    def sync_conversation_history(self, streamlit_conversation: List[Dict]):
        """Streamlit ëŒ€í™” ê¸°ë¡ê³¼ RAG ì‹œìŠ¤í…œ ë™ê¸°í™”"""
        self.conversation_history = []
        
        for message in streamlit_conversation:
            if message["role"] == "user":
                self.conversation_history.append(HumanMessage(content=message["content"]))
            else:
                self.conversation_history.append(AIMessage(content=message["content"]))
        
        print(f"ëŒ€í™” ê¸°ë¡ ë™ê¸°í™” ì™„ë£Œ: {len(self.conversation_history)}ê°œ ë©”ì‹œì§€")