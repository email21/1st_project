from datetime import datetime
import pandas as pd
import numpy as np
import logging
from pathlib import Path
from typing import Dict, List, Optional, Union, Any

class DataPreprocessor:
    """
    ê¸ˆìœµìƒí’ˆ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤
    - ì •ê¸°ì˜ˆê¸ˆ, ì ê¸ˆ, ì—°ê¸ˆì €ì¶•, ì£¼íƒë‹´ë³´ëŒ€ì¶œ, ì „ì„¸ìê¸ˆëŒ€ì¶œ, ê°œì¸ì‹ ìš©ëŒ€ì¶œ
    """

    def __init__(self, file_path: str, product_type: str) -> None:
        """
        Args:
            file_path (str): CSV íŒŒì¼ ê²½ë¡œ
            product_type (str): ìƒí’ˆ ìœ í˜• ('deposit', 'saving', 'annuity', 'mortgage', 'rent', 'credit')
        """
        self.file_path: str = file_path
        self.product_type: str = product_type
        self.df: Optional[pd.DataFrame] = None
        self.processed_df: Optional[pd.DataFrame] = None
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()

    def _setup_logging(self) -> None:
        """ë¡œê¹… ì„¤ì •"""
        log_dir = Path('../logs')
        log_dir.mkdir(parents=True, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / 'data_preprocessor.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger: logging.Logger = logging.getLogger(__name__)

    def load_data(self) -> Optional[pd.DataFrame]:
        """ë°ì´í„° ë¡œë“œ"""
        try:
            self.df = pd.read_csv(self.file_path)
            self.logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}í–‰, {len(self.df.columns)}ì—´")
            return self.df
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def get_core_columns(self) -> Dict[str, List[str]]:
        """ìƒí’ˆ ìœ í˜•ë³„ í•µì‹¬ ì»¬ëŸ¼ ì •ì˜"""
        column_mapping: Dict[str, Dict[str, List[str]]] = {
            # ì •ê¸°ì˜ˆê¸ˆ
            'deposit': {
                'core': [
                    'kor_co_nm', 'fin_prdt_nm', 'join_way',
                    'mtrt_int', 'spcl_cnd', 'join_deny',
                    'join_member', 'etc_note', 'max_limit',
                    'save_trm', 'intr_rate', 'intr_rate2'
                ]
            },
            # ì ê¸ˆ
            'saving': {
                'core': [
                    'kor_co_nm', 'fin_prdt_nm', 'join_way',
                    'mtrt_int', 'spcl_cnd', 'join_deny',
                    'join_member', 'etc_note', 'max_limit',
                    'rsrv_type_nm', 'save_trm',
                    'intr_rate', 'intr_rate2'
                ]
            },
            # ì—°ê¸ˆì €ì¶• P 16
            'annuity': {
                'core': [
                    'kor_co_nm', 'fin_prdt_nm', 'join_way',
                    'pnsn_kind_nm', 'prdt_type_nm', 'dcls_rate',
                    'guar_rate', 'btrm_prft_rate_1', 'btrm_prft_rate_2',
                    'btrm_prft_rate_3', 'etc', 'pnsn_recp_trm_nm',
                    'pnsn_entr_age_nm', 'mon_paym_atm_nm',
                    'paym_prd_nm', 'pnsn_strt_age_nm'
                ]
            },
            # ì£¼íƒë‹´ë³´ëŒ€ì¶œ
            'mortgage': {
                'core': [
                    'kor_co_nm', 'fin_prdt_nm', 'join_way',
                    'loan_inci_expn', 'erly_rpay_fee', 'dly_rate',
                    'loan_lmt', 'mrtg_type_nm', 'rpay_type_nm',
                    'lend_rate_type_nm', 'lend_rate_min',
                    'lend_rate_max', 'lend_rate_avg'
                ]
            },
            # ì „ì„¸ìê¸ˆëŒ€ì¶œ
            'rent': {
                'core': [
                    'kor_co_nm', 'fin_prdt_nm', 'join_way',
                    'loan_inci_expn', 'erly_rpay_fee', 'dly_rate',
                    'loan_lmt', 'rpay_type_nm', 'lend_rate_type_nm',
                    'lend_rate_min', 'lend_rate_max', 'lend_rate_avg'
                ]
            },
            # ê°œì¸ì‹ ìš©ëŒ€ì¶œ 12
            'credit': {
                'core': [
                    'kor_co_nm', 'fin_prdt_nm', 'join_way',
                    'crdt_prdt_type_nm', 'crdt_lend_rate_type_nm',
                    'crdt_grad_1', 'crdt_grad_4', 'crdt_grad_5',
                    'crdt_grad_6', 'crdt_grad_10', 'crdt_grad_11',
                    'crdt_grad_avg'
                ]
            }
        }
        
        return column_mapping.get(self.product_type, {})

    def clean_data(self) -> Optional[pd.DataFrame]:
        """ë°ì´í„° ì •ì œ"""
        if self.df is None:
            self.logger.error("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        # í•µì‹¬ ì»¬ëŸ¼ ì¶”ì¶œ
        column_config: Dict[str, List[str]] = self.get_core_columns()
        if not column_config:
            self.logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìƒí’ˆ ìœ í˜•: {self.product_type}")
            return None

        # í•µì‹¬ ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_cols: List[str] = [col for col in column_config['core'] if col in self.df.columns]
        self.processed_df = self.df[available_cols].copy()

        # í•„ìˆ˜ ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì œê±°
        essential_cols: List[str] = ['kor_co_nm', 'fin_prdt_nm']
        initial_count: int = len(self.processed_df)
        self.processed_df.dropna(subset=essential_cols, inplace=True)
        self.logger.info(f"ğŸ”¶ í•„ìˆ˜ ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì œê±°: {initial_count} â†’ {len(self.processed_df)}í–‰")

        # í…ìŠ¤íŠ¸ ë°ì´í„° ì •ì œ
        self.processed_df['kor_co_nm'] = self.processed_df['kor_co_nm'].str.strip()
        self.processed_df['fin_prdt_nm'] = self.processed_df['fin_prdt_nm'].str.strip()

        # ê¸ˆë¦¬ ë°ì´í„° ì •ì œ
        if self.product_type in ['deposit', 'saving', 'annuity','mortgage', 'rent', 'credit']:
            rate_columns: List[str] = [col for col in self.processed_df.columns if 'rate' in col or 'grad' in col]
            for col in rate_columns:
                if col in self.processed_df.columns:
                    self.processed_df[col] = pd.to_numeric(self.processed_df[col], errors='coerce')

        # ì¤‘ë³µ ì œê±°
        before_dedup: int = len(self.processed_df)
        self.processed_df.drop_duplicates(subset=['kor_co_nm', 'fin_prdt_nm'], inplace=True)
        self.logger.info(f"ğŸ”¶ ì¤‘ë³µ ì œê±°: {before_dedup} â†’ {len(self.processed_df)}í–‰")

        # ì—°ê¸ˆìƒí’ˆ etc ì»¬ëŸ¼ íŠ¹ë³„ ì²˜ë¦¬ ì¶”ê°€
        if self.product_type == 'annuity' and 'etc' in self.processed_df.columns:
            self.logger.info("ğŸ”§ ì—°ê¸ˆìƒí’ˆ etc ì»¬ëŸ¼ íŠ¹ë³„ ì²˜ë¦¬ ì¤‘...")
            # etc ì»¬ëŸ¼ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
            self.processed_df['etc_available'] = (
                self.processed_df['etc'].notna() &
                (self.processed_df['etc'].str.strip() != '')
            )
            # etc ì •ë³´ ì •ì œ
            self.processed_df['etc_clean'] = self.processed_df['etc'].fillna('').str.strip()
            
            # ì—°ê¸ˆ etc í†µê³„ ì¶œë ¥
            available_count: int = self.processed_df['etc_available'].sum()
            total_count: int = len(self.processed_df)
            self.logger.info(f" ğŸ“‹ etc ì •ë³´ ë³´ìœ : {available_count}/{total_count}ê°œ ìƒí’ˆ ({available_count/total_count*100:.1f}%)")

        return self.processed_df

    def create_search_text(self, row: pd.Series) -> str:
        """RAG ê²€ìƒ‰ìš© í†µí•© í…ìŠ¤íŠ¸ ìƒì„±"""
        if self.product_type == 'deposit':
            search_text: str = f"""
ìƒí’ˆëª…: {row.get('fin_prdt_nm', 'N/A')}
ê¸ˆìœµíšŒì‚¬: {row.get('kor_co_nm', 'N/A')}
ê¸°ë³¸ê¸ˆë¦¬: {row.get('intr_rate', 'N/A')}%
ìµœê³ ê¸ˆë¦¬: {row.get('intr_rate2', 'N/A')}%
ì €ì¶•ê¸°ê°„: {row.get('save_trm', 'N/A')}ê°œì›”
ìµœê³ í•œë„: {row.get('max_limit', 'N/A')}
ìš°ëŒ€ì¡°ê±´: {row.get('spcl_cnd', 'N/A')}
ê°€ì…ì œí•œ: {row.get('join_deny', 'N/A')}
ê°€ì…ëŒ€ìƒ: {row.get('join_member', 'N/A')}
ê°€ì…ë°©ë²•: {row.get('join_way', 'N/A')}
"""

        elif self.product_type == 'saving':
            search_text = f"""
ìƒí’ˆëª…: {row.get('fin_prdt_nm', 'N/A')}
ê¸ˆìœµíšŒì‚¬: {row.get('kor_co_nm', 'N/A')}
ê¸°ë³¸ê¸ˆë¦¬: {row.get('intr_rate', 'N/A')}%
ìµœê³ ê¸ˆë¦¬: {row.get('intr_rate2', 'N/A')}%
ì €ì¶•ê¸°ê°„: {row.get('save_trm', 'N/A')}ê°œì›”
ì ë¦½ìœ í˜•: {row.get('rsrv_type_nm', 'N/A')}
ìµœê³ í•œë„: {row.get('max_limit', 'N/A')}
ìš°ëŒ€ì¡°ê±´: {row.get('spcl_cnd', 'N/A')}
ê°€ì…ì œí•œ: {row.get('join_deny', 'N/A')}
ê°€ì…ëŒ€ìƒ: {row.get('join_member', 'N/A')}
ê°€ì…ë°©ë²•: {row.get('join_way', 'N/A')}
"""

        elif self.product_type == 'annuity':
            search_text = f"""
ìƒí’ˆëª…: {row.get('fin_prdt_nm', 'N/A')}
ê¸ˆìœµíšŒì‚¬: {row.get('kor_co_nm', 'N/A')}
ì—°ê¸ˆì¢…ë¥˜: {row.get('pnsn_kind_nm', 'N/A')}
ìƒí’ˆìœ í˜•: {row.get('prdt_type_nm', 'N/A')}
ê³µì‹œì´ìœ¨: {row.get('dcls_rate', 'N/A')}%
ìµœì €ë³´ì¦ì´ìœ¨: {row.get('guar_rate', 'N/A')}%
ê³¼ê±°ìˆ˜ìµë¥ 1ë…„: {row.get('btrm_prft_rate_1', 'N/A')}%
ê³¼ê±°ìˆ˜ìµë¥ 2ë…„: {row.get('btrm_prft_rate_2', 'N/A')}%
ê³¼ê±°ìˆ˜ìµë¥ 3ë…„: {row.get('btrm_prft_rate_3', 'N/A')}%
ì—°ê¸ˆìˆ˜ë ¹ê¸°ê°„: {row.get('pnsn_recp_trm_nm', 'N/A')}
ê°€ì…ì—°ë ¹: {row.get('pnsn_entr_age_nm', 'N/A')}
ì›”ë‚©ì…ê¸ˆì•¡: {row.get('mon_paym_atm_nm', 'N/A')}
ë‚©ì…ê¸°ê°„: {row.get('paym_prd_nm', 'N/A')}
ì—°ê¸ˆê°œì‹œì—°ë ¹: {row.get('pnsn_strt_age_nm', 'N/A')}
ê°€ì…ë°©ë²•: {row.get('join_way', 'N/A')}
"""

        elif self.product_type == 'mortgage':
            search_text = f"""
ìƒí’ˆëª…: {row['fin_prdt_nm']}
ê¸ˆìœµíšŒì‚¬: {row['kor_co_nm']}
ë‹´ë³´ìœ í˜•: {row.get('mrtg_type_nm', 'N/A')}
ìƒí™˜ë°©ì‹: {row.get('rpay_type_nm', 'N/A')}
ê¸ˆë¦¬ìœ í˜•: {row.get('lend_rate_type_nm', 'N/A')}
ìµœì €ê¸ˆë¦¬: {row.get('lend_rate_min', 'N/A')}%
ìµœê³ ê¸ˆë¦¬: {row.get('lend_rate_max', 'N/A')}%
í‰ê· ê¸ˆë¦¬: {row.get('lend_rate_avg', 'N/A')}%
ëŒ€ì¶œí•œë„: {row.get('loan_lmt', 'N/A')}
ê°€ì…ë°©ë²•: {row.get('join_way', 'N/A')}
ë¶€ëŒ€ë¹„ìš©: {row.get('loan_inci_expn', 'N/A')}
ì¤‘ë„ìƒí™˜ìˆ˜ìˆ˜ë£Œ: {row.get('erly_rpay_fee', 'N/A')}
ì—°ì²´ê¸ˆë¦¬: {row.get('dly_rate', 'N/A')}
"""

        elif self.product_type == 'rent':
            search_text = f"""
ìƒí’ˆëª…: {row['fin_prdt_nm']}
ê¸ˆìœµíšŒì‚¬: {row['kor_co_nm']}
ìƒí™˜ë°©ì‹: {row.get('rpay_type_nm', 'N/A')}
ê¸ˆë¦¬ìœ í˜•: {row.get('lend_rate_type_nm', 'N/A')}
ìµœì €ê¸ˆë¦¬: {row.get('lend_rate_min', 'N/A')}%
ìµœê³ ê¸ˆë¦¬: {row.get('lend_rate_max', 'N/A')}%
í‰ê· ê¸ˆë¦¬: {row.get('lend_rate_avg', 'N/A')}%
ëŒ€ì¶œí•œë„: {row.get('loan_lmt', 'N/A')}
ê°€ì…ë°©ë²•: {row.get('join_way', 'N/A')}
ë¶€ëŒ€ë¹„ìš©: {row.get('loan_inci_expn', 'N/A')}
ì¤‘ë„ìƒí™˜ìˆ˜ìˆ˜ë£Œ: {row.get('erly_rpay_fee', 'N/A')}
"""

        elif self.product_type == 'credit':
            search_text = f"""
ìƒí’ˆëª…: {row['fin_prdt_nm']}
ê¸ˆìœµíšŒì‚¬: {row['kor_co_nm']}
ëŒ€ì¶œìœ í˜•: {row.get('crdt_prdt_type_nm', 'N/A')}
ê¸ˆë¦¬ìœ í˜•: {row.get('crdt_lend_rate_type_nm', 'N/A')}
ì‹ ìš©ë“±ê¸‰ë³„ê¸ˆë¦¬:
- 900ì ì´ˆê³¼: {row.get('crdt_grad_1', 'N/A')}%
- 801-900ì : {row.get('crdt_grad_4', 'N/A')}%
- 701-800ì : {row.get('crdt_grad_5', 'N/A')}%
- 601-700ì : {row.get('crdt_grad_6', 'N/A')}%
- 501-600ì : {row.get('crdt_grad_10', 'N/A')}%
- 401-500ì : {row.get('crdt_grad_11', 'N/A')}%
í‰ê· ê¸ˆë¦¬: {row.get('crdt_grad_avg', 'N/A')}%
ê°€ì…ë°©ë²•: {row.get('join_way', 'N/A')}
"""

        else:
            search_text = f"ìƒí’ˆëª…: {row['fin_prdt_nm']}, ê¸ˆìœµíšŒì‚¬: {row['kor_co_nm']}"

        return search_text.strip()

    def add_search_text_column(self) -> Optional[pd.DataFrame]:
        """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì¶”ê°€"""
        if self.processed_df is None:
            self.logger.error("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        self.processed_df['search_text'] = self.processed_df.apply(
            lambda row: self.create_search_text(row), axis=1
        )

        self.logger.info("âœ… ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
        return self.processed_df


    def get_statistics(self) -> Optional[Dict[str, Any]]:
        """ë°ì´í„° í†µê³„ ì •ë³´ ì¶œë ¥"""
        if self.processed_df is None:
            return None

        stats: Dict[str, Any] = {
            'ì¼ì‹œ': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'ì´ ìƒí’ˆ ìˆ˜': len(self.processed_df),
            'ê¸ˆìœµíšŒì‚¬ ìˆ˜': self.processed_df['kor_co_nm'].nunique(),
            'ìƒí’ˆ ìœ í˜•': self.product_type,
            'ì£¼ìš” ê¸ˆìœµíšŒì‚¬': self.processed_df['kor_co_nm'].value_counts().head(5).to_dict()
        }

        # ìƒí’ˆë³„ ê¸ˆë¦¬ í†µê³„ ì¶”ê°€
        if self.product_type in ['deposit', 'saving']:
        # ì˜ˆì ê¸ˆ ê¸ˆë¦¬ í†µê³„
            if 'intr_rate' in self.processed_df.columns:
                valid_rates = self.processed_df['intr_rate'].dropna()
                if len(valid_rates) > 0:
                    stats['ê¸°ë³¸ê¸ˆë¦¬ ë²”ìœ„'] = f"{valid_rates.min():.2f}% ~ {valid_rates.max():.2f}%"
                    stats['ê¸°ë³¸ê¸ˆë¦¬ í‰ê· '] = f"{valid_rates.mean():.2f}%"
            
            if 'intr_rate2' in self.processed_df.columns:
                valid_rates2 = self.processed_df['intr_rate2'].dropna()
                if len(valid_rates2) > 0:
                    stats['ìµœê³ ìš°ëŒ€ê¸ˆë¦¬ ë²”ìœ„'] = f"{valid_rates2.min():.2f}% ~ {valid_rates2.max():.2f}%"
                    stats['ìµœê³ ìš°ëŒ€ê¸ˆë¦¬ í‰ê· '] = f"{valid_rates2.mean():.2f}%"
            
            # ì ê¸ˆ íŠ¹í™” í†µê³„
            if self.product_type == 'saving' and 'rsrv_type_nm' in self.processed_df.columns:
                stats['ì ë¦½ìœ í˜• ë¶„í¬'] = self.processed_df['rsrv_type_nm'].value_counts().to_dict()
    
        elif self.product_type == 'annuity':
            # ì—°ê¸ˆì €ì¶• ê¸ˆë¦¬ í†µê³„
            if 'dcls_rate' in self.processed_df.columns:
                valid_dcls = self.processed_df['dcls_rate'].dropna()
                if len(valid_dcls) > 0:
                    stats['ê³µì‹œì´ìœ¨ ë²”ìœ„'] = f"{valid_dcls.min():.2f}% ~ {valid_dcls.max():.2f}%"
                    stats['ê³µì‹œì´ìœ¨ í‰ê· '] = f"{valid_dcls.mean():.2f}%"
            
            if 'guar_rate' in self.processed_df.columns:
                valid_guar = self.processed_df['guar_rate'].dropna()
                if len(valid_guar) > 0:
                    stats['ìµœì €ë³´ì¦ì´ìœ¨ ë²”ìœ„'] = f"{valid_guar.min():.2f}% ~ {valid_guar.max():.2f}%"
                    stats['ìµœì €ë³´ì¦ì´ìœ¨ í‰ê· '] = f"{valid_guar.mean():.2f}%"
            
            # ê³¼ê±° ìˆ˜ìµë¥  í†µê³„
            profit_rates = ['btrm_prft_rate_1', 'btrm_prft_rate_2', 'btrm_prft_rate_3']
            for i, rate_col in enumerate(profit_rates, 1):
                if rate_col in self.processed_df.columns:
                    valid_profit = self.processed_df[rate_col].dropna()
                    if len(valid_profit) > 0:
                        stats[f'ê³¼ê±°ìˆ˜ìµë¥ {i}ë…„ ë²”ìœ„'] = f"{valid_profit.min():.2f}% ~ {valid_profit.max():.2f}%"
            
            # ì—°ê¸ˆ ì¢…ë¥˜ ë¶„í¬
            if 'pnsn_kind_nm' in self.processed_df.columns:
                stats['ì—°ê¸ˆì¢…ë¥˜ ë¶„í¬'] = self.processed_df['pnsn_kind_nm'].value_counts().to_dict()
    
          # ê¸ˆë¦¬ í†µê³„ (ëŒ€ì¶œ ìƒí’ˆ)
        elif self.product_type in ['mortgage', 'rent']:
            if 'lend_rate_min' in self.processed_df.columns:
                stats['ìµœì €ê¸ˆë¦¬ ë²”ìœ„'] = f"{self.processed_df['lend_rate_min'].min():.2f}% ~ {self.processed_df['lend_rate_min'].max():.2f}%"
            if 'lend_rate_max' in self.processed_df.columns:
                stats['ìµœê³ ê¸ˆë¦¬ ë²”ìœ„'] = f"{self.processed_df['lend_rate_max'].min():.2f}% ~ {self.processed_df['lend_rate_max'].max():.2f}%"
        elif self.product_type == 'credit':
            if 'crdt_grad_avg' in self.processed_df.columns:
                stats['í‰ê· ê¸ˆë¦¬ ë²”ìœ„'] = f"{self.processed_df['crdt_grad_avg'].min():.2f}% ~ {self.processed_df['crdt_grad_avg'].max():.2f}%"

        return stats
    
    def preprocess(self) -> Optional[pd.DataFrame]:
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info(f"â–¶ï¸ {self.product_type} ìƒí’ˆ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")

        # 1. ë°ì´í„° ë¡œë“œ
        if self.load_data() is None:
            return None

        # 2. ë°ì´í„° ì •ì œ
        if self.clean_data() is None:
            return None

        # 3. ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¶”ê°€
        self.add_search_text_column()

        # 4. í†µê³„ ì •ë³´ ì¶œë ¥
        stats: Optional[Dict[str, Any]] = self.get_statistics()
        if stats:
            self.logger.info("\nğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ í†µê³„:")
            for key, value in stats.items():
                self.logger.info(f" {key}: {value}")

        self.logger.info("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        return self.processed_df

    def save_processed_data(self, output_path: str) -> bool:
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        if self.processed_df is None:
            self.logger.error("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        try:
            self.processed_df.to_csv(output_path, index=False, encoding='utf-8')
            self.logger.info(f"ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
